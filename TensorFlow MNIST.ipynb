{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST in TF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('MNIST_data/',  one_hot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "epochs=20\n",
    "batch_size=128\n",
    "weight_initializer=tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=784\n",
    "n_dense_1=64\n",
    "n_dense_2=64\n",
    "n_classes=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32, [None, n_input]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(x,W,b):\n",
    "    z= tf.add(tf.matmul(x,W), b)\n",
    "    # ponieważ mamy relu activation, to pass z into relu activation function, to get output a\n",
    "    a=tf.nn.relu(z)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(x,weights, biases):\n",
    "    # 2 dense layers\n",
    "    dense_1=dense(x, weights['W1'], biases['b1'])\n",
    "    dense_2=dense(dense_1, weights['W2'], biases['b2'])\n",
    "    out_layer_z = tf.add(tf.matmul(dense_2, weights['W_out']), biases['b_out']) \n",
    "    return out_layer_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_dict={\n",
    "   'b1':tf.Variable(tf.zeros([n_dense_1])), # a 1-dimensional array, let's be zeros, wcześniej zdeifniowane: ma 64 neurons \n",
    "    'b2':tf.Variable(tf.zeros([n_dense_2])),\n",
    "    'b_out': tf.Variable(tf.zeros([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dict={\n",
    "    'W1':tf.get_variable('W1', [n_input, n_dense_1], initializer=weight_initializer),  # 1. parameter - name of variable,  \n",
    "                                  # 2. parameter:2-dim. matrix, it has to have right shape (multipl. with x)\n",
    "    'W2':tf.get_variable('W2', [n_dense_1, n_dense_2], initializer=weight_initializer),\n",
    "    'W_out':tf.get_variable('W_out', [n_dense_2, n_classes], initializer=weight_initializer)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=network(x, weights=weights_dict, biases=bias_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-2d7850245f7d>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "    # reducing of the array value to a single scalar;\n",
    "    # 2 values: prediction and the true labels y\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost)\n",
    "    #minimizing the error using GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(predictions, 1), tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_pct=tf.reduce_mean(tf.cast(correct_prediction, tf.float32))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_op=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20 epochs.\n",
      "Epoch  1: cost = 0.501: accuracy =85.40%\n",
      "Epoch  2: cost = 0.251: accuracy =92.71%\n",
      "Epoch  3: cost = 0.194: accuracy =94.35%\n",
      "Epoch  4: cost = 0.159: accuracy =95.38%\n",
      "Epoch  5: cost = 0.134: accuracy =96.08%\n",
      "Epoch  6: cost = 0.117: accuracy =96.59%\n",
      "Epoch  7: cost = 0.104: accuracy =96.95%\n",
      "Epoch  8: cost = 0.093: accuracy =97.20%\n",
      "Epoch  9: cost = 0.083: accuracy =97.53%\n",
      "Epoch 10: cost = 0.077: accuracy =97.72%\n",
      "Epoch 11: cost = 0.070: accuracy =97.92%\n",
      "Epoch 12: cost = 0.064: accuracy =98.11%\n",
      "Epoch 13: cost = 0.059: accuracy =98.23%\n",
      "Epoch 14: cost = 0.055: accuracy =98.37%\n",
      "Epoch 15: cost = 0.051: accuracy =98.50%\n",
      "Epoch 16: cost = 0.047: accuracy =98.63%\n",
      "Epoch 17: cost = 0.044: accuracy =98.69%\n",
      "Epoch 18: cost = 0.040: accuracy =98.88%\n",
      "Epoch 19: cost = 0.037: accuracy =98.97%\n",
      "Epoch 20: cost = 0.035: accuracy =99.03%\n",
      "Testing model.\n",
      "\n",
      "Test Cost: 0.085\n",
      "Test Accuracy: 97.18%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:  #create an instance of the session\n",
    "    session.run(initializer_op) # initialize variable in the session (running init._op)\n",
    "    \n",
    "    print('Training for', epochs, 'epochs.')\n",
    "    \n",
    "    #loop over epochs:\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_cost=0.0\n",
    "        avg_accuracy_pct=0.0\n",
    "        \n",
    "        \n",
    "        #how many batches: \n",
    "        n_batches=int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range (n_batches):\n",
    "            batch_x, batch_y=mnist.train.next_batch(batch_size)\n",
    "            # feeding batch to run a single step of SGD \n",
    "            # and fetch the cost & accuracy\n",
    "            \n",
    "            _, batch_cost, batch_acc=session.run([optimizer, cost, accuracy_pct], \n",
    "                                                 feed_dict={x:batch_x, y:batch_y})\n",
    "            \n",
    "            #accumulate and calculate the avg. cost/accu over all batches within the epoch\n",
    "            \n",
    "            avg_cost+=batch_cost/n_batches\n",
    "            avg_accuracy_pct+=batch_acc/n_batches\n",
    "            \n",
    "            \n",
    "        # print logs about progress, at the end of epoch:\n",
    "        print('Epoch', '%3d' %(epoch+1),\n",
    "                  ': cost = ', '{:.3f}'.format(avg_cost),\n",
    "                  ': accuracy =', '{:.2f}'.format(avg_accuracy_pct), '%', \n",
    "                  sep='')\n",
    "            \n",
    "    print('Testing model.\\n')\n",
    "            \n",
    "    test_cost=cost.eval({x:mnist.test.images, y:mnist.test.labels})\n",
    "    test_accuracy_pct=accuracy_pct.eval({x:mnist.test.images, y:mnist.test.labels})\n",
    "            \n",
    "    print('Test Cost:', '{:.3f}'.format(test_cost))\n",
    "    print('Test Accuracy: ', '{:.2f}'.format(test_accuracy_pct), '%', sep='')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
